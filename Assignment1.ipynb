{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad18f80-e7cd-432e-8295-155c65285349",
   "metadata": {},
   "source": [
    "## ASSIGNMENT-1: Transformations, Mapping and Data Representations\n",
    "\n",
    "Roll number: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0d52f-d78c-4975-9afb-b6da209573a5",
   "metadata": {},
   "source": [
    "### Instructions\n",
    " * Fill in the roll-number in the cell above.\n",
    " * Code must be written in Python in Jupyter Notebooks. We highly recommend using anaconda distribution or at the minimum, virtual environments for this assignment.\n",
    " * All the code and result files should be uploaded in the github classroom.\n",
    " * For this assignment, you will be using Open3D and AI2Thor extensively. Refer to [Open3D](http://www.open3d.org/docs/release/) and [AI2Thor](https://github.com/allenai/ai2thor) documentation.\n",
    " *  Most of the questions require you to **code your own functions** unless there is a need to call in the abilities of the mentioned libraries, such as Visualisation from Open3D. Make sure your code is modular since you will be reusing them for future assignments. All the functions related to transformation matrices, quaternions, and 3D projection are expected to be coded by you.\n",
    " *  All the representations are expected to be in a right-hand coordinate system.\n",
    "<!--  * Answer to the descriptive questions should be answered in your own words. Copy-paste answers will lead to penalty. -->\n",
    " * You could split the Jupyter Notebook cells where TODO is written, but please try to avoid splitting/changing the structure of other cells.\n",
    " * All the visualization should be done inside the notebook unless specified otherwise.\n",
    " * Plagiarism will lead to heavy penalty.\n",
    " * Commit this notebook in the repo and any other results files under the result folder in the GitHub Classroom repo. \n",
    " * Commits past the deadline will not be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb81becc-8b02-4d21-a327-3690809894cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the imports here\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d819892-cc75-4751-a471-4211c353ca02",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SECTION 1: Transformations and representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a415c1d7-d32d-4a71-8f3d-a17bfe2760d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Euler angles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73372c9-aa97-4180-bd40-d25fbc8895a2",
   "metadata": {},
   "source": [
    "a. Write a function that returns a rotation matrix given the angles (ùõº, ùõΩ, ùõæ) = (œÄ/6, 7œÄ/18, 2œÄ/9) in radians (X-Y-Z). Do not use inbuilt functions.\n",
    "\n",
    "b. Solve for angles using fsolve from scipy for three initializations of your choice and compare.\n",
    "$$M(\\alpha , \\beta ,\\gamma)=\\left[\\begin{array}{rrr}0.72907076 & -0.56745855 & 0.38268343 \\\\0.64785386 & 0.39180184 & -0.65328148 \\\\\n",
    "    0.22077409 & 0.72421137 & 0.65328148\\end{array}\\right] \n",
    "$$\n",
    "\n",
    "c. Show an example where a Gimbal lock occurs and visualize the Gimbal lock on the given point cloud, data/toothless.ply. You have to show the above by animation (rotation along each axis one by one).\n",
    "\n",
    "Hint: Use Open3D's non-blocking visualization and discretize the rotation to simulate the animation. For example, if you want to rotate by 20¬∞ around a particular axis, do so in increments of 5¬∞ 4 times to make it look like an animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a71d434f-4483-4edd-88d2-6dda431d1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 1.1 (a)\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021309b6-785b-4033-aea6-c59ebc413c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 1.1 (b)\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8698f44a-ddde-44e0-9f98-9a8728377f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 1.1 (c)\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d45694-f26d-40a1-9493-313b0822659b",
   "metadata": {},
   "source": [
    "#### 1.2: Quaternions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8715c91-9cea-4b6e-9cc7-c3ffc85a685c",
   "metadata": {},
   "source": [
    "a. Convert a rotation matrix to quaternion and vice versa. Do not use inbuilt libraries for this question.\n",
    "\n",
    "b. Perform matrix multiplication of two 3√ó3 rotation matrices and perform the same transformation in the quaternion space. Verify if the final transformation obtained in both cases is the same.\n",
    "\n",
    "c. Try to interpolate any given model between two rotation matrices and visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19682f05-1e32-4f2a-8bc0-8e427c3f6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 1.2 (a)\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb302157-1f7d-44d9-bec5-994380fbbdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 1.2 (b)\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80db19b1-57af-4bb4-bce0-0ad27b4cfb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 1.2 (c)\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278cfaec-4cb8-43fa-a332-cec8e43290d3",
   "metadata": {},
   "source": [
    "#### 1.3: Waypoint generation and trajectory visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8607de31-6da4-4fda-b47d-6600b8dbfa05",
   "metadata": {},
   "source": [
    "Read the point cloud given for this question. Make it move in a trajectory of the shape assigned to you. Find the letter assigned to you in the linked [sheet](https://docs.google.com/spreadsheets/d/1dxOndEURQky4Tp-qvxR8E1Z5gPkF6RYVifHqO5eoN7s/edit#gid=0). Corresponding to the letter, check the stylized font from data/alphabets.jpg that is to be used as the trajectory.  \n",
    "\n",
    "You need to figure out the waypoints and the transformations between each of them and visualize the overall trajectory in a smooth manner just like in question 1.1 (c). You can select any point as your start in the shape and should add a coordinate frame at the beginning point. You should keep the motion consistent and there should not be any jumps in the trajectory, this can be done by going back along the trajectory that has already been traversed.\n",
    "For eg., for letter H, if you decide to visualise the left vertical line first(|) from top to bottom, you can traverse back to the midpoint and now start going rightwards to the other vertical line(|). Basically, the motion should be all in one go without any jumps, just like that of a normal mobile robot.\n",
    "\n",
    "Also, the heading of the pointcloud should be facing the direction its moving.\n",
    "\n",
    "*The above Transformation and representation questions require you to code your own functions and only verify using inbuilt functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd860f46-7106-42ab-8207-3f987cb2a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 1.3\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f5080-93de-44d5-8eda-03d73c269a85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SECTION 2: 3D Mapping from RGB-D Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d6126a-0eb5-4239-94ee-0f0bd35dfa19",
   "metadata": {},
   "source": [
    "For this question, read the documentation of [Open3D](http://www.open3d.org/docs/release/) and [AI2Thor](https://github.com/allenai/ai2thor). Find the scene assigned to you in the linked [sheet](https://docs.google.com/spreadsheets/d/1dxOndEURQky4Tp-qvxR8E1Z5gPkF6RYVifHqO5eoN7s/edit#gid=0). \n",
    "\n",
    "2.1 Set up AI2Thor and open the scene assigned to you. Get familiar with the controller and how to change FOV, camera height, enable depth images, and move around the scene.\n",
    "\n",
    "2.2 Write a script to record the current pose, camera, and depth images after every movement (use WASD or arrow keys for movement) - current pose should be in the AI2Thor frame and at the ground level - pose format (x, y, z, q0, q1, q2, q3). You can store any additional data, if needed, in a separate file.\n",
    "\n",
    "2.3 Create a point cloud using Open3D for every pair of RGBD images - project the depth image to the 3D point cloud and assign a color to the points from the RGB images and make a point cloud using these points. Write your own functions for the projection and color assignment.\n",
    "\n",
    "2.4 Transform the point clouds to their camera frame (Figure out the transformations between the camera and pose frames) - use the function from Q1 to get the rotation matrices. The frames may not be in the same hand-system.\n",
    "\n",
    "2.5 Join all the point clouds to make a combined point cloud of the environment - also, visualize the point cloud stitching and the camera frame movement (i.e., trajectory)\n",
    "\n",
    "2.6 Create occupancy grid maps of the environment from different heights.\n",
    "\n",
    "**Helper function to generate the camera matrix given height, width and fov is given to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf915e0-5e6c-4534-a605-750b4a3aedbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai2thor_camera_matrix(h, w, fov):\n",
    "    cam_mat = np.eye(3)\n",
    "    cam_mat[0, 0] = cam_mat[1, 1] = w / (2.0 * np.tan(np.deg2rad(fov / 2)))\n",
    "    cam_mat[0, 2] = w / 2.0\n",
    "    cam_mat[1, 2] = h / 2.0\n",
    "    return cam_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef84e597-736f-4b0a-920a-71355882ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 2.1\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ccce9e2-9bd2-4843-bef9-8093080de3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 2.2\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b385b81-7ce6-4324-afba-8c53b09bff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 2.3\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3b50cc-70c7-4f6a-8812-1eb750be5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 2.4\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14bbba30-229e-4c3f-83c8-f5dcaf5f9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 2.5\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65581237-1ae4-4779-82ba-e6e22eb50487",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 2.6\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b067e96-22a5-4995-872a-5b1e3dc00227",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (OPTIONAL) SECTION 3: Mapping using 3D LiDAR\n",
    "This question is similar to section 2 but with LiDAR point cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae4e89-8798-4bca-97a1-7557d893cfb5",
   "metadata": {},
   "source": [
    "Your task is to fuse image data from a camera with the measurements from a LiDAR (a laser scanner with a 360¬∞ field-of-view that records distance measurements) and associate every point in the image with accurate distance measurements. \n",
    "\n",
    "The LiDAR‚Äôs frame is defined such that its X-axis points forward, its Y-axis points to the left, and its Z-axis points upwards. And the camera‚Äôs frame is defined such that its Z-axis points forward, X-axis points to the right, and Y-axis points downwards. The camera‚Äôs center is 8 cm below, 6 cm to the left, and 27 cm in front of the LiDAR‚Äôs center (found via extrinsic calibration and as measured by the LiDAR). Both the sensors are positioned such that the camera‚Äôs Z-axis and the LiDAR‚Äôs X-axis are perfectly parallel. Refer to the figure below for more details. \n",
    "\n",
    "<img src=\"misc/lidar.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "A LiDAR frame and its corresponding camera image have been provided as data/lidar-points.bin and data/image.png, respectively. The camera calibration matrix, K, is provided inside data/K.txt.\n",
    "\n",
    "Code for loading the LiDAR points in Python is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c319da0-6ef7-44cb-9233-afc5bbfa2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_velodyne_points(points_path):\n",
    "    points = np.fromfile(points_path, dtype=np.float32).reshape(-1, 4)\n",
    "    points = points[:,:3]                # exclude reflectance values, becomes [X Y Z]\n",
    "    points = points[1::5,:]              # remove every 5th point for display speed (optional)\n",
    "    points = points[(points[:,0] > 5)]   # remove all points behind image plane (approximate)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8450c464-6123-4c9b-a3b6-4f8808f5ef0d",
   "metadata": {},
   "source": [
    "3.1 Compute the transformation (R, t) required to transform points in the LiDAR‚Äôs frame to the\n",
    "camera‚Äôs frame. Give the transformation in both \n",
    "(a) homogeneous matrix form\n",
    "(b) XYZ Euler angles (RPY)-translation form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77bf21c5-f744-4eb1-822e-0e4013568712",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 3.1\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac9eed-c62a-4b97-b876-2bb8584f23b0",
   "metadata": {},
   "source": [
    "3.2 Then, using this computed transformation and the provided camera calibration matrix, project the LiDAR‚Äôs points onto the image plane. Use the color code (colormap) to correspond the depth of the points in the image (color is optional, but it helps in debugging). Use matplotlib or any equivalent library for plotting the points on the image. Visualize the image in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a7e6d8-99a9-459c-b162-926f8433b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Do tasks described in 3.2\n",
    "##############################################################################\n",
    "\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "\n",
    "##############################################################################\n",
    "# END OF YOUR CODE\n",
    "##############################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
